{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75000556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"sinh-arcsinh normal distribution w/o using tensorflow_probability.\n",
    "\n",
    "Functions\n",
    "---------\n",
    "cdf(x, mu, sigma, gamma, tau=None)\n",
    "    cumulative distribution function (cdf).\n",
    "\n",
    "log_prob(x, mu, sigma, gamma, tau=None)\n",
    "    log of the probability density function.\n",
    "\n",
    "mean(mu, sigma, gamma, tau=None)\n",
    "    distribution mean.\n",
    "\n",
    "median(mu, sigma, gamma, tau=None)\n",
    "    distribution median.\n",
    "\n",
    "prob(x, mu, sigma, gamma, tau=None)\n",
    "    probability density function (pdf).\n",
    "\n",
    "quantile(pr, mu, sigma, gamma, tau=None)\n",
    "    inverse cumulative distribution function.\n",
    "\n",
    "rvs(mu, sigma, gamma, tau=None, size=1)\n",
    "    generate random variates.\n",
    "\n",
    "stddev(mu, sigma, gamma, tau=None)\n",
    "    distribution standard deviation.\n",
    "\n",
    "variance(mu, sigma, gamma, tau=None)\n",
    "    distribution variance.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "* This module uses only tensorflow.  This module does not use the\n",
    "tensorflow_probability library.\n",
    "\n",
    "* The sinh-arcsinh normal distribution was defined in [1]. A more accessible\n",
    "presentation is given in [2]. \n",
    "\n",
    "* The notation and formulation used in this code was taken from [3], page 143.\n",
    "In the gamlss.dist/CRAN package the distribution is called SHASHo. \n",
    "\n",
    "* There is a typographical error in the presentation of the probability \n",
    "density function on page 143 of [3]. There is an extra \"2\" in the denomenator\n",
    "preceeding the \"sqrt{1 + z^2}\" term.\n",
    "\n",
    "References\n",
    "----------\n",
    "[1] Jones, M. C. & Pewsey, A., Sinh-arcsinh distributions,\n",
    "Biometrika, Oxford University Press, 2009, 96, 761-780.\n",
    "DOI: 10.1093/biomet/asp053.\n",
    "\n",
    "[2] Jones, C. & Pewsey, A., The sinh-arcsinh normal distribution,\n",
    "Significance, Wiley, 2019, 16, 6-7.\n",
    "DOI: 10.1111/j.1740-9713.2019.01245.x.\n",
    "https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2019.01245.x\n",
    "\n",
    "[3] Stasinopoulos, Mikis, et al. (2021), Distributions for Generalized \n",
    "Additive Models for Location Scale and Shape, CRAN Package.\n",
    "https://cran.r-project.org/web/packages/gamlss.dist/gamlss.dist.pdf\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import tensorflow as tf\n",
    "\n",
    "__author__ = \"Randal J. Barnes and Elizabeth A. Barnes\"\n",
    "__date__ = \"14 January 2022\"\n",
    "\n",
    "\n",
    "SQRT_TWO = 1.4142135623730950488016887\n",
    "ONE_OVER_SQRT_TWO = 0.7071067811865475244008444\n",
    "TWO_PI = 6.2831853071795864769252868\n",
    "SQRT_TWO_PI = 2.5066282746310005024157653\n",
    "ONE_OVER_SQRT_TWO_PI = 0.3989422804014326779399461\n",
    "\n",
    "\n",
    "def _jones_pewsey_P(q):\n",
    "    \"\"\"P_q function from page 764 of [1].\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    q : float, array like\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    P_q : array like of same shape as q.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * The formal equation is\n",
    "\n",
    "            jp = 0.25612601391340369863537463 * (\n",
    "                scipy.special.kv((q + 1) / 2, 0.25) +\n",
    "                scipy.special.kv((q - 1) / 2, 0.25)\n",
    "            )\n",
    "\n",
    "        The strange constant 0.25612... is \"sqrt( sqrt(e) / (8*pi) )\" computed\n",
    "        with a high-precision calculator.  The special function\n",
    "\n",
    "            scipy.special.kv\n",
    "\n",
    "        is the Modified Bessel function of the second kind: K(nu, x).\n",
    "\n",
    "    * But, we cannot use the scipy.special.kv function during tensorflow\n",
    "        training.  This code uses a 6th order polynomial approximation in\n",
    "        place of the formal function.\n",
    "\n",
    "    * This approximation is well behaved for 0 <= q <= 10. Since q = 1/tau\n",
    "        or q = 2/tau in our applications, the approximation is well behaved\n",
    "        for 1/10 <= tau < infty.\n",
    "\n",
    "    \"\"\"\n",
    "    # A 6th order polynomial approximation of log(_jones_pewsey_P) for the\n",
    "    # range 0 <= q <= 10.  Over this range, the max |error|/true < 0.0025.\n",
    "    # These coefficients were computed by minimizing the maximum relative\n",
    "    # error, and not by a simple least squares regression.\n",
    "    coeffs = [\n",
    "        9.37541380598926e-06,\n",
    "        -0.000377732651131894,\n",
    "        0.00642826706073389,\n",
    "        -0.061281078712518,\n",
    "        0.390956214318641,\n",
    "        -0.0337884356755193,\n",
    "        0.00248824801827172\n",
    "    ]\n",
    "    return tf.math.exp(tf.math.polyval(coeffs, q))\n",
    "\n",
    "\n",
    "def shash_cdf(x, mu, sigma, gamma, tau=None):\n",
    "    \"\"\"Cumulative distribution function (cdf).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float (batch size x 1) Tensor\n",
    "        The values at which to compute the probability density function.\n",
    "\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter. Must be the same shape as x.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as x.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as x.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor or None\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as x. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F : float (batch size x 1) Tensor.\n",
    "        The computed cumulative probability distribution function (cdf)\n",
    "        evaluated at the values of x.  F has the same shape as x.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * This function uses the tensorflow.math.erf function rather than the\n",
    "    tensorflow_probability normal distribution functions.\n",
    "\n",
    "    \"\"\"\n",
    "    y = (x - mu) / sigma    \n",
    "    \n",
    "    if tau is None:\n",
    "        z = tf.math.sinh(tf.math.asinh(y) - gamma)\n",
    "    else:\n",
    "        z = tf.math.sinh(tau * tf.math.asinh(y) - gamma)\n",
    "\n",
    "    return 0.5 * (1.0 + tf.math.erf(ONE_OVER_SQRT_TWO * z))\n",
    "\n",
    "\n",
    "# def shash_log_prob(x, mu, sigma, gamma, tau=None):\n",
    "def shash_log_prob(x, mu, sigma, gamma, tau):\n",
    "    \"\"\"Log-probability density function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float (batch size x 1) Tensor\n",
    "        The values at which to compute the probability density function.\n",
    "\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter. Must be the same shape as x.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as x.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as x.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as x. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    f : float (batch size x 1) Tensor.\n",
    "        The natural logarithm of the computed probability density function\n",
    "        evaluated at the values of x.  f has the same shape as x.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * This function is included merely to emulate the tensorflow_probability\n",
    "    distributions.\n",
    "\n",
    "    \"\"\"\n",
    "    return tf.math.log(shash_prob(x, mu, sigma, gamma, tau))\n",
    "\n",
    "\n",
    "def shash_mean(mu, sigma, gamma, tau):\n",
    "    \"\"\"The distribution mean.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as mu.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : float (batch size x 1) Tensor.\n",
    "        The computed distribution mean values.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * This equation for evX can be found on page 764 of [1].\n",
    "\n",
    "    \"\"\"\n",
    "    if tau is None:\n",
    "        evX = tf.math.sinh(gamma) * 1.35453080648132  \n",
    "    else:\n",
    "        evX = tf.math.sinh(gamma / tau) * _jones_pewsey_P(1.0 / tau)\n",
    "\n",
    "    return mu + sigma * evX\n",
    "\n",
    "\n",
    "def shash_median(mu, sigma, gamma, tau):\n",
    "    \"\"\"The distribution median.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as mu.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : float (batch size x 1) Tensor.\n",
    "        The computed distribution mean values.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * This code uses the basic formula:\n",
    "\n",
    "        E(a*X + b) = a*E(X) + b\n",
    "\n",
    "    * The E(X) is computed using the moment equation given on page 764 of [1].\n",
    "\n",
    "    \"\"\"\n",
    "    if tau is None:\n",
    "        return mu + sigma * tf.math.sinh(gamma)\n",
    "    else:\n",
    "        return mu + sigma * tf.math.sinh(gamma / tau)\n",
    "\n",
    "\n",
    "def shash_prob(x, mu, sigma, gamma, tau):\n",
    "    \"\"\"Probability density function (pdf).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float (batch size x 1) Tensor\n",
    "        The values at which to compute the probability density function.\n",
    "\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter. Must be the same shape as x.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as x.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as x.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as x. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    f : float (batch size x 1) Tensor.\n",
    "        The computed probability density function evaluated at the values of x.\n",
    "        f has the same shape as x.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * This code uses the equations on page 143 of [3], and the associated\n",
    "    notation.\n",
    "\n",
    "    \"\"\"\n",
    "    y = (x - mu) / sigma\n",
    "    \n",
    "    if tau is None:\n",
    "        rsqr = tf.math.square(tf.math.sinh(tf.math.asinh(y) - gamma))\n",
    "        return (\n",
    "            ONE_OVER_SQRT_TWO_PI\n",
    "            / sigma\n",
    "            * tf.math.sqrt((1 + rsqr) / (1 + tf.math.square(y)))\n",
    "            * tf.math.exp(-rsqr / 2)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        rsqr = tf.math.square(tf.math.sinh(tau * tf.math.asinh(y) - gamma))\n",
    "        return (\n",
    "            ONE_OVER_SQRT_TWO_PI\n",
    "            * (tau / sigma)\n",
    "            * tf.math.sqrt((1 + rsqr) / (1 + tf.math.square(y)))\n",
    "            * tf.math.exp(-rsqr / 2)\n",
    "        )\n",
    "\n",
    "\n",
    "def shash_quantile(pr, mu, sigma, gamma, tau):\n",
    "    \"\"\"Inverse cumulative distribution function.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    pr : float (batch size x 1) Tensor.\n",
    "        The probabilities at which to compute the values.\n",
    "\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter. Must be the same shape as pr.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as pr.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as pr.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as pr. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : float (batch size x 1) Tensor.\n",
    "        The computed values at the specified probabilities. f has the same\n",
    "        shape as pr.\n",
    "\n",
    "    \"\"\"\n",
    "    z = tf.math.ndtri(pr)\n",
    "            \n",
    "    if tau is None:\n",
    "        return mu + sigma * tf.math.sinh(tf.math.asinh(z) + gamma)    \n",
    "    else:\n",
    "        return mu + sigma * tf.math.sinh((tf.math.asinh(z) + gamma) / tau)\n",
    "\n",
    "\n",
    "def shash_rvs(mu, sigma, gamma, tau, size=1):\n",
    "    \"\"\"Generate an array of random variates.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    mu : float or double scalar\n",
    "        The location parameter.\n",
    "\n",
    "    sigma : float or double scalar\n",
    "        The scale parameter. Must be strictly positive.\n",
    "\n",
    "    gamma : float or double scalar\n",
    "        The skewness parameter.\n",
    "\n",
    "    tau : float or double scalar, or None\n",
    "        The tail-weight parameter. Must be strictly positive. \n",
    "        If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    size : int or tuple of ints, default=1.\n",
    "        The number of random variates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : double ndarray of size=size\n",
    "        The generated random variates.\n",
    "\n",
    "    \"\"\"\n",
    "    z = scipy.stats.norm.rvs(size=size)\n",
    "    \n",
    "    if tau is None:\n",
    "        return mu + sigma * np.sinh(np.arcsinh(z) + gamma)\n",
    "    else:\n",
    "        return mu + sigma * np.sinh((np.arcsinh(z) + gamma) / tau)\n",
    "\n",
    "\n",
    "def shash_stddev(mu, sigma, gamma, tau):\n",
    "    \"\"\"The distribution standard deviation.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as mu.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : float (batch size x 1) Tensor.\n",
    "        The computed distribution standard deviation values.\n",
    "\n",
    "    \"\"\"\n",
    "    return tf.math.sqrt(variance(mu, sigma, gamma, tau))\n",
    "\n",
    "\n",
    "def shash_variance(mu, sigma, gamma, tau):\n",
    "    \"\"\"The distribution variance.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    mu : float (batch size x 1) Tensor\n",
    "        The location parameter.\n",
    "\n",
    "    sigma : float (batch size x 1) Tensor\n",
    "        The scale parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu.\n",
    "\n",
    "    gamma : float (batch size x 1) Tensor\n",
    "        The skewness parameter. Must be the same shape as mu.\n",
    "\n",
    "    tau : float (batch size x 1) Tensor\n",
    "        The tail-weight parameter. Must be strictly positive. Must be the same\n",
    "        shape as mu. If tau is None then the default value of tau=1 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : float (batch size x 1) Tensor.\n",
    "        The computed distribution variance values.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * This code uses two basic formulas:\n",
    "\n",
    "        var(X) = E(X^2) - (E(X))^2\n",
    "        var(a*X + b) = a^2 * var(X)\n",
    "\n",
    "    * The E(X) and E(X^2) are computed using the moment equations given on\n",
    "    page 764 of [1].\n",
    "\n",
    "    \"\"\"\n",
    "    if tau is None:\n",
    "        evX = tf.math.sinh(gamma) * 1.35453080648132\n",
    "        evX2 = (tf.math.cosh(2 * gamma) * 3.0 - 1.0) / 2\n",
    "    else:\n",
    "        evX = tf.math.sinh(gamma / tau) * _jones_pewsey_P(1.0 / tau)\n",
    "        evX2 = (tf.math.cosh(2 * gamma / tau) * _jones_pewsey_P(2.0 / tau) - 1.0) / 2\n",
    "        \n",
    "    return tf.math.square(sigma) * (evX2 - tf.math.square(evX))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
